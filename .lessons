# FP8 Flash Attention Assembly Kernel - Lessons Learned

## Critical Discoveries (Priority Order)

### 1. FP8 FORMAT: MFMA Uses e4m3fn (OCP), NOT e4m3fnuz!

**THE MOST CRITICAL FINDING**: Using the wrong FP8 format causes 2× output values!

| Value    | e4m3fnuz byte | e4m3fn (OCP) byte |
|----------|---------------|-------------------|
| 0.015625 | 16            | 8                 |
| 0.03125  | 24            | 16                |
| 0.0625   | 32            | 24                |
| 0.125    | 40            | 32                |

**Rules**:
- `v_cvt_pk_fp8_f32` produces OCP (e4m3fn) format bytes
- In PyTorch: use `torch.float8_e4m3fn`, NOT `torch.float8_e4m3fnuz`
- If loading FP8 from global memory, ensure it's stored in OCP format

**Test**: `test_pack_debug.s` compares manual packing vs `v_cvt_pk_fp8_f32`

---

### 2. P Redistribution is REQUIRED for PV MFMA

After QK MFMA, thread t has:
- `P[Q_rows_interleaved, K=t%32]` - 16 Q values at ONE K column

For PV MFMA A operand, thread t needs:
- `P[Q=t%32, K_range]` - ONE Q value at 8 K columns

**The layouts are TRANSPOSED** - must redistribute via LDS:

```assembly
// Write P to LDS: P[Q, K] at offset Q*32 + K
v_and_b32_e32 v4, 31, v0              // K = tid % 32
v_add_u32_e32 v5, LDS_P_OFFSET, v4
ds_write_b8 v5, v3                    // Write for Q=0
ds_write_b8 v5, v3 offset:32          // Write for Q=1
// ... repeat for all Q rows

s_barrier

// Read P for PV MFMA: P[Q=tid%32, K_start..K_start+8]
v_and_b32_e32 v6, 31, v0              // Q = tid % 32
v_lshrrev_b32_e32 v7, 5, v0           // K_group = tid / 32
v_lshlrev_b32_e32 v7, 3, v7           // K_start = K_group * 8
v_lshlrev_b32_e32 v6, 5, v6           // Q * 32
v_add_u32_e32 v6, v6, v7              // + K_start
ds_read_b64 v[32:33], v6              // Read 8 FP8 P values
```

**Why uniform P works without redistribution**: When all P values are identical, the transposed read gives same values.

**Test**: `test_p_redistrib.s` and `test_nonuniform_p.s` verify this pattern.

---

### 3. MFMA 32x32x16 Operand and Output Layout

**A operand (32M × 16K)**:
- Thread t provides `A[M=t%32, K=(t/32)*8:(t/32)*8+8]`
- Threads 0-31: K=0..7 for M rows 0-31
- Threads 32-63: K=8..15 for M rows 0-31

**B operand (16K × 32N)**:
- Thread t provides `B[K=(t/32)*8:(t/32)*8+8, N=t%32]`
- Threads 0-31: K=0..7 for N cols 0-31
- Threads 32-63: K=8..15 for N cols 0-31

**Output (32M × 32N) - INTERLEAVED**:
- Thread t owns `C[M_rows_interleaved, N=t%32]`
- Threads 0-31: M rows 0,1,2,3, 8,9,10,11, 16,17,18,19, 24,25,26,27
- Threads 32-63: M rows 4,5,6,7, 12,13,14,15, 20,21,22,23, 28,29,30,31

**Scatter store pattern** for interleaved output:
```assembly
v_and_b32_e32 v3, 31, v0              // N = tid % 32
v_lshrrev_b32_e32 v4, 5, v0           // M_base = (tid/32)*4
// Store v48-v51 to M_base+0,1,2,3
// Store v52-v55 to M_base+8,9,10,11
// Store v56-v59 to M_base+16,17,18,19
// Store v60-v63 to M_base+24,25,26,27
```

---

### 4. FP8 Precision Limitations

FP8 e4m3 has limited precision for larger values:
- Values 0-16: Exact representation
- Values 17,19,21,23,25,27,29,31: Round to nearest even (17→16, 19→20, etc.)
- Max representable: ~240

**Tests should use values in exact FP8 range** to distinguish algorithm bugs from precision loss.

---

## Verified Test Patterns

| Test | Pattern | Expected | Purpose |
|------|---------|----------|---------|
| `test_mfma_k_sum.s` | A=1, B=K | 120 | K reduction correctness |
| `test_mfma_m_index.s` | A=M, B=1 | M*16 | M-row distribution |
| `test_attention_pv.s` | P=1/16, V=d | d | D value propagation |
| `test_p_redistrib.s` | P=(k+1)/16 via LDS | 8.5 | P redistribution |
| `test_full_attn_v2.s` | P=1/16, V=d/32 | d/32 | Full PV computation |
| `test_nonuniform_p.s` | P=(k+1)/136, V=1 | 0.98 | Non-uniform P |

**All tests use non-uniform inputs** to avoid false positives from uniform data.

---

## ds_read_b64_tr_b8 Transpose Read (Reference)

**Base address scaling**: `base = position * 8`

```assembly
v_and_b32_e32 v6, 15, v0           // D = lane % 16
v_lshlrev_b32_e32 v6, 3, v6        // base = D * 8 (REQUIRED!)
ds_read_b64_tr_b8 v[30:31], v6     // Reads with stride 16
```

**LDS Layout for tr_b8**: 16-byte rows, `V[K, D]` at `LDS[K*16 + D]`

**Limitation**: Reliable only for positions 0-127 (first 128 bytes).

---

## Key Lessons

1. **Always test with non-uniform inputs** - uniform values hide bugs
2. **Verify FP8 format matches MFMA** - e4m3fn (OCP), not e4m3fnuz
3. **MFMA output is interleaved** - not contiguous M rows
4. **P redistribution cannot be avoided** - QK output layout differs from PV input
5. **Use scatter stores** for interleaved output pattern
6. **Check FP8 precision** - some values round, affecting test expectations

---

## File Reference

```
hsa/gfx950/fmha_v3_fwd_fp8/
├── test_mfma_k_sum.s       # K reduction test
├── test_mfma_m_index.s     # M-row distribution test
├── test_attention_pv.s     # Basic P×V test
├── test_p_redistrib.s      # P redistribution via LDS
├── test_full_attn_v2.s     # Full attention with e4m3fn
├── test_nonuniform_p.s     # Non-uniform P values
├── test_pack_debug.s       # FP8 packing comparison
├── test_mfma_2x_debug.s    # 2× factor debugging
├── test_mfma_layouts.py    # Python reference patterns
└── .progress               # Development progress tracking
```
