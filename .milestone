# FP8 Flash Attention - Milestones

## Goal
FP8 kernel with >30% TF/s improvement over BF16 (~1000 â†’ >1300 TF/s)

---

## Phase 2: Single-Tile HD=128 âœ… COMPLETE
Working kernel: `test_full_hd128.s`
- All 7 rigorous tests passing

---

## Phase 3: K-tile Loop âœ… COMPLETE

### Key Fixes
1. **v1 must be recalculated before K load** - The VGPR offset was getting stale
2. **Buffer descriptor size must be -1 (max)** - Size=4096 blocked tile 1+ access
3. **Proper O rescaling** - correction = exp((old_max - new_max) * scale)
4. **Use new_max for P computation** - Was using tile_max instead of global max

### Test Results (After Buffer Descriptor Fix)
```
seq_len=32  (1 tile):  max_error=0.088 âœ…
seq_len=64  (2 tiles): max_error=0.073 âœ…  
seq_len=96  (3 tiles): max_error=0.044 âœ…
seq_len=128 (4 tiles): max_error=0.035 âœ…
```

### Notes
- Multi-tile errors now DECREASE with more tiles (proper accumulation)
- FP8 quantization noise is the primary error source

---

## Phase 4: Full HD=128 Output ðŸ”œ NEXT

### Todo
- [ ] Extend PV MFMA to cover all 4 HD tiles (cols 0-127)
- [ ] Update output store for full 128 columns
- [ ] Run benchmark against BF16

---

## Files

```
hsa/gfx950/fmha_v3_fwd_fp8/
â”œâ”€â”€ test_full_hd128.s       # Working single-tile kernel âœ…
â”œâ”€â”€ fwd_fp8_kloop.s         # K-loop kernel âœ… (first 32 HD cols)
â”œâ”€â”€ test_kloop_attn.py      # K-loop attention test âœ…
â”œâ”€â”€ test_rigorous.py        # Phase 2 tests âœ…
```

---

## LDS Layout (K-loop kernel)

| Offset | Size | Content |
|--------|------|---------|
| 0 | 4KB | Q (stays for all tiles) |
| 4096 | 4KB | K â†’ P (reused per tile) |
| 8192 | 4KB | V |
| **Total** | **12KB** | |
