# FP8 Flash Attention ASM Kernel - Milestone Tracker

## TARGET
- >1300 TF/s at B=1, H=40, S=32130, D=128
- 30%+ faster than BF16 ASM (1016 TF/s)

## BASELINE (verified 2025-01-16)
| Kernel | TF/s | Notes |
|--------|------|-------|
| BF16 ASM | 1016 | Reference |
| Triton FP8 | 1294 | Target to beat |

## CURRENT STATUS

### Phase: MULTI-BLOCK IMPLEMENTATION
- K=64 MFMA working (2x efficiency) ✓
- K-loop working (numerically correct) ✓
- Single-block only (perf gap) ←
- Multi-block support (in progress)
- LDS swizzle (pending)
- Pipelining (pending)

### Working Files
- `fwd_fp8_k64_kloop_acc.s` - Single-block K-loop with K=64 MFMA
- `fwd_fp8_kloop.s` - Full attention (K=16, non-performant reference)

### Active Path
See `multiblock.path` for current approach details

## ROADMAP

1. [DONE] K=64 MFMA implementation
2. [DONE] K-loop iteration
3. [NOW] Multi-block support (workgroup_id for Q-tile/head)
4. [NEXT] LDS swizzle (stride-132 or BF16 pattern)
5. [NEXT] K-tile load pipelining
6. [NEXT] Full attention integration (softmax + PV)

## BLOCKERS INVESTIGATED

### Triton HSACO Direct Launch (BLOCKED)
- Preload mechanism changes SGPR layout
- HIP packed buffer has ~56 byte limit
- Decision: Build custom kernel instead
