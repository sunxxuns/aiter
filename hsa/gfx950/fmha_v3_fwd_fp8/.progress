# FP8 Flash Attention Kernel Progress

## Current Status: FULL HEAD_DIM=128 WORKING (v4)

### Completed Steps

1. ✅ **Basic FP8 kernel structure** (v1)
   - Kernel launch, args parsing, thread mapping

2. ✅ **QK MFMA computation** (v1)
   - Q/K loading from global memory to LDS
   - ds_read_b64_tr_b8 for transpose read
   - v_mfma_f32_32x32x16_fp8_fp8 for 8 K-tiles (K=0..127)
   - Accumulated FP32 results in v[32:47]

3. ✅ **Online softmax** (v1)
   - Row-wise max finding with v_max_f32
   - Exp computation with v_exp_f32
   - Running sum accumulation
   - Final 1/sum normalization

4. ✅ **PV MFMA computation** (v2 - NUMERICALLY CORRECT)
   - V loading: 16 strided flat_load_ubyte per thread
   - LDS layout: K-inner V[D,K] at offset D*32 + K
   - ds_read_b64 for MFMA B operand
   - P→FP8 packing with v_cvt_pk_fp8_f32
   - v_mfma_f32_32x32x16_fp8_fp8 for 2 K-groups (K=0..31)

5. ✅ **Output normalization and store** (v2)
   - Multiply by 1/sum
   - Store FP32 output to global memory

6. ✅ **Debug store removal** (v3_clean)
   - Removed all debug stores
   - Performance: 4.58us → 3.11us (32% faster)

7. ✅ **D-tile loop for full head_dim=128** (v4)
   - Loops 4x to process D=0..31, 32..63, 64..95, 96..127
   - P→FP8 conversion done once before loop (reused)
   - Performance: 5.15us for full head_dim (better than expected 4×3.11=12.4us)

### Current Kernel Performance

| Kernel | Time | Notes |
|--------|------|-------|
| fwd_hd128_fp8_v3.s | 4.58 us | With debug stores, D=0..31 only |
| fwd_hd128_fp8_v3_clean.s | 3.11 us | No debug stores, D=0..31 only |
| fwd_hd128_fp8_v4.s | 5.15 us | Full head_dim=128, D-tile loop |

### Numerical Accuracy (Verified)

**v3_clean (D=0..31):**
- Controlled V pattern: ✓ Expected 15.5, Got 15.5
- All zeros V: ✓ Expected 0.0, Got 0.0  
- Constant V=1: ✓ Expected 1.0, Got 1.0
- PyTorch reference: ✓ Max error 0.36

**v4 (full head_dim=128):**
- All 4 D-tiles: ✓ Controlled pattern 15.5
- PyTorch reference per D-tile: max_err 0.33-0.48, mean_err ~0.10

### Next Steps

1. **Multi-wave support** (NEXT)
   - Currently single wave (64 threads)
   - Need multiple waves for larger sequences

2. **Performance optimization**
   - Coalesced V loading (replace strided loads)
   - Better LDS utilization
   - Instruction scheduling

### Files

```
fwd_hd128_fp8_v2.s       - Working kernel with debug stores (reference)
fwd_hd128_fp8_v3.s       - Working kernel with debug stores (copy of v2)
fwd_hd128_fp8_v3_clean.s - D=0..31 only, no debug stores
fwd_hd128_fp8_v4.s       - Full head_dim=128 with D-tile loop
```

### Key Learnings

1. **ds_read_b64_tr_b8** has addressing limitations (128-byte window)
2. **Strided V loads** work but are slow (16 flat_load_ubyte per thread)
3. **K-inner LDS layout** V[D,K] enables simple ds_read_b64 for MFMA
4. **Debug stores** can be safely removed by replacing with s_nop

### Architecture Notes

- Target: AMD gfx950
- MFMA: v_mfma_f32_32x32x16_fp8_fp8 (64 FLOPs per instruction)
- Threads: 64 (single wave)
- LDS: 32KB allocated
- Tile: 32×32 attention with 128-dim heads
