# FP8 Flash Attention - Numerics

## Status: Phase 2 Complete ✅

### Single-Tile Tests (SEQ=32)
All 7 rigorous tests passing:

| Test | Max Error | Status |
|------|-----------|--------|
| Transformer embeddings | 0.086 | ✅ |
| Peaked attention | 0.004 | ✅ |
| Position patterns | 0.005 | ✅ |
| Numerical edge cases | 0.047 | ✅ |
| Row/column confusion | 0.000 | ✅ |
| Accumulation order | 0.000 | ✅ |
| Specific patterns | 0.006 | ✅ |

### FP8 Precision Characteristics
- Expected max error: ~0.05-0.1 for normalized inputs
- Higher error in peaked distributions due to quantization
- Error comes from `v_cvt_pk_fp8_f32` conversion, not kernel logic

### Verified Behaviors
1. **Row-wise softmax**: Confirmed via test_softmax_check.py
2. **S^T = K @ Q^T**: Matches BF16 reference pattern
3. **P transpose**: Correct reordering for PV MFMA

---

## Phase 3: K-tile Loop (In Progress)

### buffer_load Validation ✅
Debug kernel verified:
- `buffer_load_dword v, voff, s[8:11], soff offen` works
- Scalar offset (soff) can be used for tile advancement
- Buffer descriptor: s[8:9]=addr, s10=size, s11=0x20000

### Required: `.args` Metadata
Kernel must include `.args:` section in `.amdgpu_metadata`:
```yaml
.args:
  - {.name: ptr_O, .size: 8, .offset: 0, .value_kind: global_buffer, .address_space: global}
  - {.name: ptr_K, .size: 8, .offset: 8, .value_kind: global_buffer, .address_space: global}
```

Without this, kernel launch causes memory fault at address (nil).

---

## Test Commands

```bash
# Main test suite
python test_rigorous.py

# buffer_load debug
python debug_bufload.py
```
