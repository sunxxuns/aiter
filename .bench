# FP8 Flash Attention - Benchmarks

## Status: Phase 2 Correctness Only

Performance benchmarking not yet started.
Current focus: K-tile loop implementation for seq_len > 32.

---

## Benchmark Command

```bash
python /sgl-workspace/sglang/benchmark/kernels/bench_mi350_fmha_asm.py --seq-len 32130
```

---

## Target Performance

| Config | BF16 Baseline | FP8 Target | Improvement |
|--------|---------------|------------|-------------|
| seq=32130 | ~1000 TF/s | >1300 TF/s | +30% |

---

## Current Kernel Capabilities

| Feature | Status |
|---------|--------|
| head_dim=128 | âœ… |
| seq_len=32 (single tile) | âœ… |
| seq_len>32 (K-loop) | ðŸ”„ In Progress |
| Batch/heads | Not yet |

---

## Performance Expectations

FP8 benefits:
1. 2x throughput on FP8 MFMA vs BF16 MFMA
2. 2x memory bandwidth (half element size)

Overhead:
1. FP8 conversion (`v_cvt_pk_fp8_f32`)
2. F32 softmax maintained (same as BF16)

Net expected: 30-50% TF/s improvement
